{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Engineering Portfolio","text":"<p>Welcome! This site highlights selected projects. Each page includes a problem \u2192 approach \u2192 results summary, architecture diagram, and links to code snippets.</p> <p>For Shure (Senior Embedded Software Engineer role): see the Role Fit page to view a concise mapping between the job requirements and project evidence in this portfolio.</p>"},{"location":"DEPLOY/","title":"Deploying this portfolio (GitHub Pages \u2014 MkDocs)","text":"<p>This repo contains a GitHub Actions workflow that builds the MkDocs site and deploys to the <code>gh-pages</code> branch automatically on push to <code>main</code> or <code>master</code>.</p> <p>Quick checklist 1. Create a new GitHub repository (e.g., <code>eriksangeorzan-portfolio</code>) and push the <code>my-portfolio</code> folder to it (or push this repo as-is). 2. Ensure the default branch is <code>main</code> (or <code>master</code>); the workflow triggers on pushes to that branch. 3. Enable GitHub Actions in the repository (usually enabled by default). The workflow file is <code>.github/workflows/deploy.yml</code>. 4. After the first successful run, the site is published on the <code>gh-pages</code> branch. You can configure the repository's Pages settings to use the <code>gh-pages</code> branch and the <code>/</code> root (or leave Actions to manage it automatically).</p> <p>Notes - The workflow uses <code>GITHUB_TOKEN</code> automatically (no extra secret needed). - If you prefer Netlify or Vercel, you can connect the repository there and set the build command to <code>mkdocs build</code> and publish the contents of the <code>site/</code> directory.</p>"},{"location":"role-fit/","title":"Role Fit \u2014 Shure Senior Embedded Software Engineer (mapping)","text":"<p>Context: This page maps the Shure job requirements to specific project evidence in this portfolio. Each bullet below points to one or more projects and a one-line explanation of how the project demonstrates the skill.</p> <ul> <li>Design, develop and test embedded software and associated components for audio products (C/C++):</li> <li>Real-Time Audio Separation \u2014 Teensy firmware, I2S/UART C/C++ code, Raspberry Pi processing and multithreaded Python demos demonstrating low-latency embedded audio capture and processing.</li> <li> <p>Stratum Synthesizer \u2014 assembly-level audio engine and drivers showing deep knowledge of audio signal path and constraints.</p> </li> <li> <p>Hardware drivers, embedded software applications, audio and control networking (C/C++):</p> </li> <li>Stratum Synthesizer \u2014 speaker and SD drivers, low-level peripheral control.</li> <li> <p>Zumo Shield Robot \u2014 STM32 PWM, timers, UART and GPIO; illustrates driver usage and hardware control.</p> </li> <li> <p>Real-time, multitasking, RTOS concepts and debugging (Embedded Linux/FreeRTOS/etc):</p> </li> <li>Real-Time Audio Separation \u2014 real-time constraints, multicore/multithreaded processing and synchronization.</li> <li> <p>Zumo Shield Robot \u2014 real-time control loop design and hardware timing considerations (timers, interrupts, PWM).</p> </li> <li> <p>Networking &amp; protocols (UART, I2S, possibility to work with Ethernet/TCP/UDP/Wi-Fi):</p> </li> <li> <p>Real-Time Audio Separation \u2014 I2S audio capture and UART streaming; demonstrates protocol-level understanding and embedded networking concepts.</p> </li> <li> <p>Software architecture, design, and testing (reviews, unit/integration tests):</p> </li> <li> <p>All projects include design notes and reports; the portfolio includes a test-oriented project (Toyota Auto-Validation) and unit tests in other repos (e.g., the archived Glasgow repo had tests). I prioritize clear documentation and testability.</p> </li> <li> <p>Hardware debugging and release processes:</p> </li> <li> <p>Zumo Shield Robot and Stratum Synthesizer show hardware bring-up, telemetry, and iterative debugging workflows; Toyota demo shows validation and reporting practices.</p> </li> <li> <p>Version control and documentation:</p> </li> <li>Full repositories and README/USAGE/OVERVIEW docs are included with each project; this portfolio itself is version-controlled and deploy-ready.</li> </ul>"},{"location":"projects/","title":"Projects","text":"<p>Browse the projects below. Each card links to a detailed page with context, design notes, and selected code.</p> <ul> <li>Real-Time Audio Separation of Human Voices \u2014 Real-time audio acquisition (Teensy + Raspberry Pi), I2S, UART, multithreaded processing, and ICA-based separation.</li> <li>Stratum Synthesizer (Assembly) \u2014 Low-level audio synthesis and drivers (speaker, SD, touchscreen) implemented in assembly for constrained systems.</li> <li>Zumo Shield Robot Navigation (C) \u2014 STM32-based navigation and control with PWM motor control, timers, GPIO and UART telemetry.</li> <li>Toyota Auto-Validation (Harman) Demo \u2014 Validation and test automation demo for embedded system testing and reports.</li> <li>Resume &amp; Cover Letter \u2014 Tailored resume and a Shure-focused cover letter with contact links.</li> </ul>"},{"location":"projects/glasgow-index-analyzer/","title":"Glasgow Index Analyzer (ARCHIVED)","text":"<p>Removed from public portfolio</p> <p>This project has been removed from the public portfolio at the owner's request (2026-01-06). The original content has been archived in <code>docs/projects/archive/glasgow-index-analyzer.md</code>. If you need to restore the page, contact the owner.</p>"},{"location":"projects/glasgow-index-analyzer/#how-to-run-reproduce","title":"How to run / reproduce","text":"<ul> <li>Create a Python virtual environment and install dependencies:</li> </ul> <pre><code>python -m venv venv\nvenv\\Scripts\\activate     # on Windows\npip install -r requirements.txt\n</code></pre> <ul> <li>Example analysis command:</li> </ul> <pre><code>python glasgow_index_analyzer.py --analyze --oscar-data-root &lt;DATA_DIR&gt; --settings-history-csv &lt;settings.csv&gt; --oscar-csv &lt;oscar.csv&gt; --output ./my_results.csv\n</code></pre> <ul> <li>Run tests / validation:</li> </ul> <pre><code>python -m pytest -q\n# or run specific tests\npython test_sleep_integration.py\npython test_sleep_mapping.py\n</code></pre> <ul> <li>See the repository README for additional example commands and plotting options.</li> </ul>"},{"location":"projects/real-time-audio-separation/","title":"Real-Time Audio Separation of Human Voices","text":"<p>Summary: Real-time source separation project combining embedded Teensy audio acquisition (I2S), UART streaming, Raspberry Pi multicore processing, and a Python GUI for real-time playback and visualization. Demonstrates embedded audio capture, DSP algorithms, synchronization, and performance engineering.</p> <p>Problem: Build a small-form-factor array to capture and separate human voices in real-time.</p> <p>Approach: Implement low-latency audio capture on Teensy (I2S), transmit via UART to a Raspberry Pi, perform online ICA/FFT-based processing with multiprocessing, and provide a multithreaded Python GUI for playback/visualization.</p> <p>Results: Working demo with real-time playback, written report and poster, performance tradeoffs documented.</p> <p>Relevant files - <code>Project Samples/Real-Time Audio Separation of Human Voices (Python, C)/src/valuecheck.ino</code> (Teensy firmware) - <code>.../src/analyze_fft1024o.cpp</code>, <code>setI2Sfreq.cpp</code> (embedded audio handling) - <code>.../src/multiproc_cogent.py</code>, <code>ui3_1_maxplayback.py</code> (Raspberry Pi processing &amp; GUI) - Report and slides: <code>2021-Team-2-final.pdf</code>, <code>2021-Team-2-slides.pdf</code>.</p> <p>Skills demonstrated - C/C++ on embedded platforms (I2S, UART), Python multiprocessing and multithreading - Real-time DSP (FFT, ICA), FIR filtering (low-pass) - Hardware synchronization using GPIO, performance tuning and profiling</p> <p>Why this is relevant to Shure - Directly maps to audio capture and real-time DSP experience required for professional audio products; shows experience with embedded audio pipelines, low-latency processing, and cross-platform integration.</p>"},{"location":"projects/real-time-audio-separation/#how-to-run-reproduce","title":"How to run / reproduce","text":"<p>Hardware - Teensy boards with Audio Shield (or equivalent), a Raspberry Pi (4 recommended), microphones (or test audio), and a UART connection between Teensy and Pi.</p> <p>Quick steps - Run the self-contained demo: open <code>src_computer_runnable_demo/</code> and follow its README. - On the Raspberry Pi (or laptop):   - Create a Python virtualenv and install any dependencies (if present).   - Run:</p> <pre><code>python3 src/multiproc_cogent.py\npython3 src/ui3_1_maxplayback.py\n</code></pre> <ul> <li>On each Teensy: flash <code>src/valuecheck.ino</code> (use Arduino IDE / Teensy Loader) and set I2S/UART parameters as described in <code>OVERVIEW.txt</code>.</li> </ul> <p>Notes - Real-time performance depends on available CPU cores and tuning parameters \u2014 see <code>OVERVIEW.txt</code> and <code>USAGE.txt</code> for recommended settings and bottlenecks.</p>"},{"location":"projects/real-time-audio-separation/#downloads","title":"Downloads","text":"<ul> <li>Final report (PDF)</li> <li>Slide deck (PDF)</li> <li>Poster (PDF)</li> <li>Demo video (MP4)</li> <li>Runnable demo (zip)</li> </ul>"},{"location":"projects/real-time-audio-separation/#what-to-inspect","title":"What to inspect","text":"<ul> <li>See the Final report for design decisions, synchronization approach, and performance analysis.</li> <li>Play the Demo video for the live system behavior and slide commentary.</li> <li>Download the Runnable demo to run the self-contained demo locally (instructions in <code>USAGE.txt</code>).</li> </ul>"},{"location":"projects/resume-cover/","title":"Resume &amp; Cover Letter","text":""},{"location":"projects/resume-cover/#resume","title":"Resume","text":"<p>Open published resume in a new tab</p>"},{"location":"projects/resume-cover/#cover-letter","title":"Cover Letter","text":"<p>Open published cover letter in a new tab</p>"},{"location":"projects/stratum-synthesizer/","title":"Stratum Synthesizer (Assembly)","text":"<p>Summary: A hand-crafted audio synthesizer implemented largely in assembly with low-level drivers for speaker output, SD card access, SDRAM, and touchscreen I/O\u2014focused on efficiency and driver-level control.</p> <p>Problem: Produce a functional synthesizer on constrained embedded hardware with multiple instrument voices and low-latency control.</p> <p>Approach: Implement synthesis routines and driver code in assembly for tight control over timing and memory; build drivers for SD I/O and speaker output.</p> <p>Results: Full synthesizer with multiple instruments and a touchscreen interface; source demonstrates low-level driver work and audio path implementation.</p> <p>Relevant files - <code>Project Samples/Stratum Synthesizer (Assembly)/Code/speaker_driver.e</code> - <code>.../sd_read_driver.e</code>, <code>sdram_read_driver.e</code>, <code>touchscreen_driver.e</code>, <code>synth</code> modules - Written report and presentation in the root of the project folder.</p> <p>Skills demonstrated - Assembly-level optimization and hardware driver development - Real-time audio signal generation and low-latency control - Debugging constrained systems and interfacing with peripherals</p> <p>Why this is relevant to Shure - Shows low-level embedded audio engineering and driver development experience important for firmware that directly handles audio devices and peripheral interfaces.</p>"},{"location":"projects/stratum-synthesizer/#how-to-run-reproduce","title":"How to run / reproduce","text":"<ul> <li>Hardware &amp; toolchain: See <code>Stratum Written Report.pdf</code> for details on required hardware and the toolchain used in the course. The project was built and tested on the original target hardware described in the report.</li> <li>To run on target hardware:</li> <li>Copy <code>combined.raw</code> to the root of an SD card used by the target board.</li> <li>Load <code>test_top.e</code> (or <code>test_GUI.e</code> for interactive tests) as the main program using the course toolchain/toolchain loader.</li> </ul>"},{"location":"projects/stratum-synthesizer/#downloads","title":"Downloads","text":"<ul> <li>Stratum Written Report (PDF)</li> <li>Presentation (PPTX)</li> <li>Code (zip)</li> </ul>"},{"location":"projects/stratum-synthesizer/#what-to-inspect","title":"What to inspect","text":"<ul> <li>Read the Stratum Written Report for architecture and driver design notes.</li> <li>Inspect <code>speaker_driver.e</code> and the <code>synth</code> modules inside the code zip to see low-level driver logic and instrument synthesis routines.</li> </ul>"},{"location":"projects/toyota-auto-validation/","title":"Toyota Auto-Validation (Harman) Demo","text":"<p>Summary: Demo materials and validation artifacts focused on test and validation workflows for embedded systems.</p> <p>Problem: Demonstrate automated validation and reporting for an embedded automotive system.</p> <p>Approach: Create demo recordings and validation scripts (C# demo artifacts included in the project folder) showing system-level test scenarios and reporting. The software automatically and programmatically updates the properties of the function generator machine to match the input values from the code based on what is required for each given data set and frequency response scenario (such as <code>DAB Stereo: Speed, -30dB, 80mph</code>).</p> <p>Results: Demo video and notes showcasing test methodology and results.</p> <p>Relevant files - <code>Project Samples/DEMO_ Toyota Auto-Validation Software, Harman (C#)/IMG_0092.mov</code></p> <p>Skills demonstrated - Test/validation mindset, automation and reporting - Communication of validation results to stakeholders</p> <p>Why this is relevant to Shure - Highlights validation and verification experience which complements firmware development and release processes.</p>"},{"location":"projects/toyota-auto-validation/#how-to-run-reproduce","title":"How to run / reproduce","text":"<ul> <li>Play the demo video: <code>Project Samples/DEMO_ Toyota Auto-Validation Software, Harman (C#)/IMG_0092.mov</code> to view the validation walkthrough.</li> </ul>"},{"location":"projects/toyota-auto-validation/#downloads-video","title":"Downloads &amp; Video","text":"<ul> <li>Demo Video: toyota-demo.mp4 (compressed, 83.2 MB, ~1.5 min)</li> <li>Transcoded from original 1080p MOV (161 MB) using H.264 at 7.5 Mbps to balance quality and size.</li> <li>Original footage: Available on request if you'd like the uncompressed version.</li> </ul>"},{"location":"projects/zumo-shield-robot/","title":"Zumo Shield Robot Navigation (C)","text":"<p>Summary: STM32-based robot navigation project showing motor control, sensor IO, PWM, timers, and UART telemetry using the STM32 HAL and C.</p> <p>Problem: Implement reliable line-following and navigation on a Zumo robot using the STM32 microcontroller.</p> <p>Approach: Use STM32 HAL to manage PWM motor control, GPIO sensors, timers and UART for debug telemetry; implement sensor scanning and corrective control logic in C.</p> <p>Results: Working line-following implementation with telemetry and documented firmware (<code>main.c</code>).</p> <p>Relevant files - <code>Project Samples/Zumo Shield Robot Navigation (C)/Line follower/main.c</code></p> <p>Skills demonstrated - Embedded C programming on STM32 (PWM, timers, UART, GPIO) - Low-level hardware control and real-time loop design for control systems - Hardware debugging and interfacing with sensors and actuators</p> <p>Why this is relevant to Shure - Demonstrates embedded firmware development, hardware driver use and debugging\u2014core skills for device firmware and low-level audio peripherals.</p>"},{"location":"projects/zumo-shield-robot/#how-to-run-reproduce","title":"How to run / reproduce","text":"<ul> <li>Open the <code>Line follower</code> project in STM32CubeIDE (the project was created with STM32 Cube tools).</li> <li>Build and flash the firmware to the STM32 (Zumo) board.</li> <li>Open a serial console to the board (LPUART1 at 115200 baud) to view <code>printf</code> telemetry and debug messages.</li> <li>Verify motor and sensor wiring matches pins in <code>main.c</code>; adjust PWM/drive parameters as needed and test in a controlled environment.</li> </ul>"},{"location":"projects/zumo-shield-robot/#downloads","title":"Downloads","text":"<ul> <li>Line follower code (zip)</li> </ul>"},{"location":"projects/zumo-shield-robot/#what-to-inspect","title":"What to inspect","text":"<ul> <li>Open <code>main.c</code> in the zip and inspect the sensor scan and correction logic \u2014 this is where hardware timing and PWM control are implemented.</li> </ul>"},{"location":"projects/archive/glasgow-index-analyzer/","title":"Glasgow Index Analyzer (ARCHIVED)","text":"<p>Status: Archived \u2014 removed from public portfolio by owner on 2026-01-06.</p> <p>The original contents of this file have been moved here for safe-keeping. The public portfolio no longer links to this page; contact the repository owner to restore it.</p>"},{"location":"projects/archive/glasgow-index-analyzer/#glasgow-index-analyzer-python","title":"Glasgow Index Analyzer (Python)","text":"<p>Summary: A signal-processing and analysis pipeline for physiological data (CPAP/EDFs) with test automation, plotting and integration with sleep data.</p> <p>Problem \u2192 Approach \u2192 Results - Problem: Analyze PAP device data to compute and study a bespoke \"Glasgow Index\" and related metrics across large datasets. - Approach: Build a Python pipeline to ingest device logs, integrate external sleep data, compute metrics, and automate plotting and correlation analysis; include unit tests for key components. - Results: Reusable analysis scripts, automated tests, and visualizations (heatmaps, trend plots).</p> <p>Relevant files - <code>auto-glasgow-index/glasgow_index_analyzer.py</code>, <code>analyze_settings.py</code>, tests (<code>test_sleep_integration.py</code>, etc.)</p> <p>Skills demonstrated - Signal processing, pipeline engineering, test-driven development - Data integration and analysis, plotting and result communication</p> <p>Notes - This file was archived and removed from the public project listing per owner request (2026-01-06). If you need access or to restore it, contact the owner directly.</p>"}]}
{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Erik Sangeorzan: Engineering Portfolio","text":"<p>Welcome to my engineering portfolio showcasing selected projects in embedded software, audio processing, and robotics. Each project page includes a structured Problem, Approach, and Results summary, technical details, and downloadable artifacts.</p>"},{"location":"#quick-navigation","title":"Quick Navigation","text":"<ul> <li>Projects: Browse all featured projects</li> <li>Role Fit: Mapping to Shure Senior Embedded Software Engineer requirements</li> <li>Resume &amp; Cover Letter: Tailored application materials</li> </ul>"},{"location":"DEPLOY/","title":"Deploying this portfolio (GitHub Pages - MkDocs)","text":"<p>This repo contains a GitHub Actions workflow that builds the MkDocs site and deploys to the <code>gh-pages</code> branch automatically on push to <code>main</code> or <code>master</code>.</p> <p>Quick checklist 1. Create a new GitHub repository (e.g., <code>eriksangeorzan-portfolio</code>) and push the <code>my-portfolio</code> folder to it (or push this repo as-is). 2. Ensure the default branch is <code>main</code> (or <code>master</code>); the workflow triggers on pushes to that branch. 3. Enable GitHub Actions in the repository (usually enabled by default). The workflow file is <code>.github/workflows/deploy.yml</code>. 4. After the first successful run, the site is published on the <code>gh-pages</code> branch. You can configure the repository's Pages settings to use the <code>gh-pages</code> branch and the <code>/</code> root (or leave Actions to manage it automatically).</p> <p>Notes - The workflow uses <code>GITHUB_TOKEN</code> automatically (no extra secret needed). - If you prefer Netlify or Vercel, you can connect the repository there and set the build command to <code>mkdocs build</code> and publish the contents of the <code>site/</code> directory.</p>"},{"location":"resume-cover/","title":"Resume &amp; Cover Letter","text":""},{"location":"resume-cover/#resume","title":"Resume","text":"<p>Open published resume in a new tab</p>"},{"location":"resume-cover/#cover-letter","title":"Cover Letter","text":"<p>Open published cover letter in a new tab</p>"},{"location":"role-fit/","title":"Role Fit: Shure Senior Embedded Software Engineer","text":"<p>Context: This page maps the Shure job requirements to specific project evidence in this portfolio. Each section below corresponds to a key requirement, with links to relevant projects and explanations of how they demonstrate the skill.</p>"},{"location":"role-fit/#design-develop-and-test-embedded-software-and-associated-components-for-audio-products-cc","title":"Design, develop and test embedded software and associated components for audio products (C/C++)","text":"<ul> <li>Real-Time Audio Separation: Teensy firmware, I2S/UART C/C++ code, Raspberry Pi processing and multithreaded Python demos demonstrating low-latency embedded audio capture and processing.</li> <li>Analyzing Tennis Matches Based on Audio: MATLAB-based audio signal processing and algorithm development (transient detection, spectral analysis) relevant to audio product R&amp;D.</li> <li>Stratum Synthesizer: assembly-level audio engine and drivers showing deep knowledge of audio signal path and constraints.</li> </ul>"},{"location":"role-fit/#hardware-drivers-embedded-software-applications-audio-and-control-networking-cc","title":"Hardware drivers, embedded software applications, audio and control networking (C/C++)","text":"<ul> <li>Stratum Synthesizer: speaker and SD drivers, low-level peripheral control.</li> <li>Zumo Shield Robot: STM32 PWM, timers, UART and GPIO; illustrates driver usage and hardware control.</li> </ul>"},{"location":"role-fit/#real-time-multitasking-rtos-concepts-and-debugging-embedded-linuxfreertosetc","title":"Real-time, multitasking, RTOS concepts and debugging (Embedded Linux/FreeRTOS/etc)","text":"<ul> <li>Real-Time Audio Separation: real-time constraints, multicore/multithreaded processing and synchronization.</li> <li>Zumo Shield Robot: real-time control loop design and hardware timing considerations (timers, interrupts, PWM).</li> </ul>"},{"location":"role-fit/#networking-protocols-uart-i2s-possibility-to-work-with-ethernettcpudpwi-fi","title":"Networking &amp; protocols (UART, I2S, possibility to work with Ethernet/TCP/UDP/Wi-Fi)","text":"<ul> <li>Real-Time Audio Separation: I2S audio capture and UART streaming; demonstrates protocol-level understanding and embedded networking concepts.</li> </ul>"},{"location":"role-fit/#software-architecture-design-and-testing-reviews-unitintegration-tests","title":"Software architecture, design, and testing (reviews, unit/integration tests)","text":"<ul> <li>All projects include design notes and reports; the portfolio includes a test-oriented project (Toyota Auto-Validation) and unit tests in other repos (e.g., the archived Glasgow repo had tests). I prioritize clear documentation and testability.</li> </ul>"},{"location":"role-fit/#hardware-debugging-and-release-processes","title":"Hardware debugging and release processes","text":"<ul> <li>Zumo Shield Robot and Stratum Synthesizer show hardware bring-up, telemetry, and iterative debugging workflows; Toyota demo shows validation and reporting practices.</li> </ul>"},{"location":"role-fit/#version-control-and-documentation","title":"Version control and documentation","text":"<ul> <li>Full repositories and README/USAGE/OVERVIEW docs are included with each project; this portfolio itself is version-controlled and deploy-ready.</li> </ul>"},{"location":"projects/","title":"Projects","text":"<p>Browse the projects below. Each card links to a detailed page with context, design notes, and selected code.</p> <ul> <li>Real-Time Audio Separation of Human Voices: Real-time audio acquisition (Teensy + Raspberry Pi), I2S, UART, multithreaded processing, and ICA-based separation.</li> <li>Stratum Synthesizer (Assembly): Low-level audio synthesis and drivers (speaker, SD, touchscreen) implemented in assembly for constrained systems.</li> <li>Zumo Shield Robot Navigation (C): STM32-based navigation and control with PWM motor control, timers, GPIO and UART telemetry.</li> <li>Toyota Auto-Validation (Harman) Demo: Validation and test automation demo for embedded system testing and reports.</li> <li>Analyzing Tennis Matches Based on Audio (MATLAB): Signal processing project detecting ball hits and tracking score from match audio.</li> </ul>"},{"location":"projects/glasgow-index-analyzer/","title":"Glasgow Index Analyzer (ARCHIVED)","text":"<p>Removed from public portfolio</p> <p>This project has been removed from the public portfolio at the owner's request (2026-01-06). The original content has been archived in <code>docs/projects/archive/glasgow-index-analyzer.md</code>. If you need to restore the page, contact the owner.</p>"},{"location":"projects/glasgow-index-analyzer/#how-to-run-reproduce","title":"How to run / reproduce","text":"<ul> <li>Create a Python virtual environment and install dependencies:</li> </ul> <pre><code>python -m venv venv\nvenv\\Scripts\\activate     # on Windows\npip install -r requirements.txt\n</code></pre> <ul> <li>Example analysis command:</li> </ul> <pre><code>python glasgow_index_analyzer.py --analyze --oscar-data-root &lt;DATA_DIR&gt; --settings-history-csv &lt;settings.csv&gt; --oscar-csv &lt;oscar.csv&gt; --output ./my_results.csv\n</code></pre> <ul> <li>Run tests / validation:</li> </ul> <pre><code>python -m pytest -q\n# or run specific tests\npython test_sleep_integration.py\npython test_sleep_mapping.py\n</code></pre> <ul> <li>See the repository README for additional example commands and plotting options.</li> </ul>"},{"location":"projects/real-time-audio-separation/","title":"Real-Time Audio Separation of Human Voices","text":"<p>Summary: Real-time source separation project combining embedded Teensy audio acquisition (I2S), UART streaming, Raspberry Pi multicore processing, and a Python GUI for real-time playback and visualization. Demonstrates embedded audio capture, DSP algorithms, synchronization, and performance engineering.</p> <p>Problem: Build a small-form-factor array to capture and separate human voices in real-time.</p> <p>Approach: Implement low-latency audio capture on Teensy (I2S), transmit via UART to a Raspberry Pi, perform online ICA/FFT-based processing with multiprocessing, and provide a multithreaded Python GUI for playback/visualization.</p> <p>Results: Working demo with real-time playback, written report and poster, performance tradeoffs documented.</p>"},{"location":"projects/real-time-audio-separation/#skills-demonstrated","title":"Skills demonstrated","text":"<ul> <li>C/C++ on embedded platforms (I2S, UART), Python multiprocessing and multithreading</li> <li>Real-time DSP (FFT, ICA), FIR filtering (low-pass)</li> <li>Hardware synchronization using GPIO, performance tuning and profiling</li> </ul>"},{"location":"projects/real-time-audio-separation/#why-this-is-relevant-to-shure","title":"Why this is relevant to Shure","text":"<ul> <li>Directly maps to audio capture and real-time DSP experience required for professional audio products; shows experience with embedded audio pipelines, low-latency processing, and cross-platform integration.</li> </ul>"},{"location":"projects/real-time-audio-separation/#how-to-run-reproduce","title":"How to run / reproduce","text":"<p>Hardware:</p> <ul> <li>Teensy boards with Audio Shield (or equivalent), a Raspberry Pi (4 recommended), microphones (or test audio), and a UART connection between Teensy and Pi.</li> </ul> <p>Quick steps:</p> <ul> <li>Run the self-contained demo: open <code>src_computer_runnable_demo/</code> and follow its README.</li> <li>On the Raspberry Pi (or laptop):</li> <li>Create a Python virtualenv and install any dependencies (if present).</li> <li>Run:</li> </ul> <pre><code>python3 src/multiproc_cogent.py\npython3 src/ui3_1_maxplayback.py\n</code></pre> <ul> <li>On each Teensy: flash <code>src/valuecheck.ino</code> (use Arduino IDE / Teensy Loader) and set I2S/UART parameters as described in <code>OVERVIEW.txt</code>.</li> </ul> <p>Notes:</p> <ul> <li>Real-time performance depends on available CPU cores and tuning parameters; see <code>OVERVIEW.txt</code> and <code>USAGE.txt</code> for recommended settings and bottlenecks.</li> </ul>"},{"location":"projects/real-time-audio-separation/#downloads","title":"Downloads","text":"<ul> <li>Final report (PDF)</li> <li>Slide deck (PDF)</li> <li>Poster (PDF)</li> <li>Demo video (MP4)</li> <li>Runnable demo (zip)</li> </ul>"},{"location":"projects/real-time-audio-separation/#what-to-inspect","title":"What to inspect","text":"<ul> <li>See the Final report for design decisions, synchronization approach, and performance analysis.</li> <li>Play the Demo video for the live system behavior and slide commentary.</li> <li>Download the Runnable demo to run the self-contained demo locally (instructions in <code>USAGE.txt</code>).</li> <li>Inspect <code>src/valuecheck.ino</code> for Teensy I2S/UART firmware and <code>src/multiproc_cogent.py</code> for the Python multiprocessing implementation.</li> </ul>"},{"location":"projects/stratum-synthesizer/","title":"Stratum Synthesizer (Assembly)","text":"<p>Summary: A hand-crafted audio synthesizer implemented largely in assembly with low-level drivers for speaker output, SD card access, SDRAM, and touchscreen I/O - focused on efficiency and driver-level control.</p> <p>Problem: Produce a functional synthesizer on constrained embedded hardware with multiple instrument voices and low-latency control.</p> <p>Approach: Implement synthesis routines and driver code in assembly for tight control over timing and memory; build drivers for SD I/O and speaker output.</p> <p>Results: Full synthesizer with multiple instruments and a touchscreen interface; source demonstrates low-level driver work and audio path implementation.</p>"},{"location":"projects/stratum-synthesizer/#skills-demonstrated","title":"Skills demonstrated","text":"<ul> <li>Assembly-level optimization and hardware driver development</li> <li>Real-time audio signal generation and low-latency control</li> <li>Debugging constrained systems and interfacing with peripherals</li> </ul>"},{"location":"projects/stratum-synthesizer/#why-this-is-relevant-to-shure","title":"Why this is relevant to Shure","text":"<ul> <li>Shows low-level embedded audio engineering and driver development experience important for firmware that directly handles audio devices and peripheral interfaces.</li> </ul>"},{"location":"projects/stratum-synthesizer/#how-to-run-reproduce","title":"How to run / reproduce","text":"<ul> <li>Hardware &amp; toolchain: See <code>Stratum Written Report.pdf</code> for details on required hardware and the toolchain used in the course. The project was built and tested on the original target hardware described in the report.</li> <li>To run on target hardware:</li> <li>Copy <code>combined.raw</code> to the root of an SD card used by the target board.</li> <li>Load <code>test_top.e</code> (or <code>test_GUI.e</code> for interactive tests) as the main program using the course toolchain/toolchain loader.</li> </ul>"},{"location":"projects/stratum-synthesizer/#downloads","title":"Downloads","text":"<ul> <li>Stratum Written Report (PDF)</li> <li>Presentation (PPTX)</li> <li>Code (zip)</li> </ul>"},{"location":"projects/stratum-synthesizer/#what-to-inspect","title":"What to inspect","text":"<ul> <li>Read the Stratum Written Report for architecture and driver design notes.</li> <li>Inspect <code>speaker_driver.e</code>, <code>sd_read_driver.e</code>, and the <code>synth</code> modules inside the code zip to see low-level driver logic and instrument synthesis routines.</li> </ul>"},{"location":"projects/tennis-audio-analysis/","title":"Analyzing Tennis Matches Based on Audio (MATLAB)","text":"<p>Summary: A signal processing project using MATLAB to analyze audio from tennis matches to detect ball hits, identify \"out\" calls vs. applause, and track game score automatically.</p> <p>Problem: Automate the tracking of tennis match events and scoring using only audio cues.</p> <p>Approach: Developed MATLAB algorithms to detect transients (ball hits), spectral features for applause vs. net hits, and implemented a state machine to track scoring.</p> <p>Results: Successfully detected ball hits and applause in test clips; identified limitations in net hit detection for specific rallies.</p>"},{"location":"projects/tennis-audio-analysis/#skills-demonstrated","title":"Skills demonstrated","text":"<ul> <li>Audio Signal Processing (MATLAB)</li> <li>Algorithm Development (transient detection, spectral analysis)</li> <li>State Machine Logic for scoring</li> </ul>"},{"location":"projects/tennis-audio-analysis/#why-this-is-relevant-to-shure","title":"Why this is relevant to Shure","text":"<ul> <li>Demonstrates fundamental audio signal processing and algorithm development skills using MATLAB, a standard tool for DSP prototyping.</li> </ul>"},{"location":"projects/tennis-audio-analysis/#project-website","title":"Project website","text":"<p>For a detailed breakdown of the methodology and results, visit the project website.</p>"},{"location":"projects/tennis-audio-analysis/#how-to-run-reproduce","title":"How to run / reproduce","text":"<ul> <li>Requirements: MATLAB.</li> <li>Run <code>main.m</code> in MATLAB.</li> <li>The script analyzes the audio, prints the game score to the console, and generates plots for detected events.</li> <li>Note: The current algorithm has a known issue missing a net hit in rally 4, which affects scoring in subsequent rallies.</li> </ul>"},{"location":"projects/tennis-audio-analysis/#downloads","title":"Downloads","text":"<ul> <li>Code (zip)</li> </ul>"},{"location":"projects/tennis-audio-analysis/#what-to-inspect","title":"What to inspect","text":"<ul> <li>Check <code>findBallHit.m</code> to see the transient detection logic.</li> <li>See <code>main.m</code> for the integration of detection algorithms into the game loop.</li> </ul>"},{"location":"projects/toyota-auto-validation/","title":"Toyota Auto-Validation (Harman) Demo","text":"<p>Summary: Automated validation demo for embedded automotive systems, showcasing programmatic control of test equipment and data-driven testing scenarios using C# scripts.</p> <p>Problem: Demonstrate automated validation and reporting for an embedded automotive system.</p> <p>Approach: Create demo recordings and validation scripts (C# demo artifacts included in the project folder) showing system-level test scenarios and reporting. The software automatically and programmatically updates the properties of the function generator machine to match the input values from the code based on what is required for each given data set and frequency response scenario (such as <code>DAB Stereo: Speed, -30dB, 80mph</code>).</p> <p>Results: Demo video and notes showcasing test methodology and results.</p>"},{"location":"projects/toyota-auto-validation/#skills-demonstrated","title":"Skills demonstrated","text":"<ul> <li>Test/validation mindset, automation and reporting</li> <li>Communication of validation results to stakeholders</li> </ul>"},{"location":"projects/toyota-auto-validation/#why-this-is-relevant-to-shure","title":"Why this is relevant to Shure","text":"<ul> <li>Highlights validation and verification experience which complements firmware development and release processes.</li> </ul>"},{"location":"projects/toyota-auto-validation/#how-to-run-reproduce","title":"How to run / reproduce","text":"<ul> <li>Play the demo video below to view the validation walkthrough.</li> </ul>"},{"location":"projects/toyota-auto-validation/#downloads-video","title":"Downloads &amp; video","text":"<ul> <li>Demo video: toyota-demo.mp4</li> </ul>"},{"location":"projects/toyota-auto-validation/#what-to-inspect","title":"What to inspect","text":"<ul> <li>Watch the demo video to see the automated test setup and equipment control in action.</li> </ul>"},{"location":"projects/zumo-shield-robot/","title":"Zumo Shield Robot Navigation (C)","text":"<p>Summary: STM32-based robot navigation project showing motor control, sensor IO, PWM, timers, and UART telemetry using the STM32 HAL and C.</p> <p>Problem: Implement reliable line-following and navigation on a Zumo robot using the STM32 microcontroller.</p> <p>Approach: Use STM32 HAL to manage PWM motor control, GPIO sensors, timers and UART for debug telemetry; implement sensor scanning and corrective control logic in C.</p> <p>Results: Working line-following implementation with telemetry and documented firmware (<code>main.c</code>).</p>"},{"location":"projects/zumo-shield-robot/#skills-demonstrated","title":"Skills demonstrated","text":"<ul> <li>Embedded C programming on STM32 (PWM, timers, UART, GPIO)</li> <li>Low-level hardware control and real-time loop design for control systems</li> <li>Hardware debugging and interfacing with sensors and actuators</li> </ul>"},{"location":"projects/zumo-shield-robot/#why-this-is-relevant-to-shure","title":"Why this is relevant to Shure","text":"<ul> <li>Demonstrates embedded firmware development, hardware driver use and debugging - core skills for device firmware and low-level audio peripherals.</li> </ul>"},{"location":"projects/zumo-shield-robot/#how-to-run-reproduce","title":"How to run / reproduce","text":"<ul> <li>Open the <code>Line follower</code> project in STM32CubeIDE (the project was created with STM32 Cube tools).</li> <li>Build and flash the firmware to the STM32 (Zumo) board.</li> <li>Open a serial console to the board (LPUART1 at 115200 baud) to view <code>printf</code> telemetry and debug messages.</li> <li>Verify motor and sensor wiring matches pins in <code>main.c</code>; adjust PWM/drive parameters as needed and test in a controlled environment.</li> </ul>"},{"location":"projects/zumo-shield-robot/#downloads-presentation-video","title":"Downloads &amp; presentation video","text":"<ul> <li>Line follower code (zip)</li> <li>Presentation video</li> </ul>"},{"location":"projects/zumo-shield-robot/#what-to-inspect","title":"What to inspect","text":"<ul> <li>Open <code>main.c</code> in the zip and inspect the sensor scan and correction logic; this is where hardware timing and PWM control are implemented.</li> </ul>"},{"location":"projects/archive/glasgow-index-analyzer/","title":"Glasgow Index Analyzer (ARCHIVED)","text":"<p>Status: Archived - removed from public portfolio by owner on 2026-01-06.</p> <p>The original contents of this file have been moved here for safe-keeping. The public portfolio no longer links to this page; contact the repository owner to restore it.</p>"},{"location":"projects/archive/glasgow-index-analyzer/#glasgow-index-analyzer-python","title":"Glasgow Index Analyzer (Python)","text":"<p>Summary: A signal-processing and analysis pipeline for physiological data (CPAP/EDFs) with test automation, plotting and integration with sleep data.</p> <p>Problem: Analyze PAP device data to compute and study a bespoke \"Glasgow Index\" and related metrics across large datasets.</p> <p>Approach: Build a Python pipeline to ingest device logs, integrate external sleep data, compute metrics, and automate plotting and correlation analysis; include unit tests for key components.</p> <p>Results: Reusable analysis scripts, automated tests, and visualizations (heatmaps, trend plots).</p> <p>Relevant files - <code>auto-glasgow-index/glasgow_index_analyzer.py</code>, <code>analyze_settings.py</code>, tests (<code>test_sleep_integration.py</code>, etc.)</p> <p>Skills demonstrated - Signal processing, pipeline engineering, test-driven development - Data integration and analysis, plotting and result communication</p> <p>Notes - This file was archived and removed from the public project listing per owner request (2026-01-06). If you need access or to restore it, contact the owner directly.</p>"}]}